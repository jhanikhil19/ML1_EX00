{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qb3VJ_gbmmzx"
   },
   "source": [
    "# Numpy Basics\n",
    "\n",
    "This tutorial covers the following topics:\n",
    "\n",
    "- Working with numerical data in Python\n",
    "- Going from Python lists to Numpy arrays\n",
    "- Multi-dimensional Numpy arrays and their benefits\n",
    "- Array operations, broadcasting, indexing, and slicing\n",
    "- Working with CSV data files using Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agddj9AbmwJz"
   },
   "source": [
    "The \"data\" typically refers to numerical data, e.g., stock prices, sales figures, sensor measurements, sports scores, database tables, etc. The [Numpy](https://numpy.org) library provides specialized data structures, functions, and other tools for numerical computing in Python. Let's work through an example to see why & how to use Numpy for working with numerical data.\n",
    "\n",
    "\n",
    "> Suppose we want to use climate data like the temperature, rainfall, and humidity to determine if a region is well suited for growing apples. A simple approach for doing this would be to formulate the relationship between the annual yield of apples (tons per hectare) and the climatic conditions like the average temperature (in degrees Fahrenheit), rainfall (in  millimeters) & average relative humidity (in percentage) as a linear equation.\n",
    ">\n",
    "> `yield_of_apples = w1 * temperature + w2 * rainfall + w3 * humidity`\n",
    "\n",
    "We're expressing the yield of apples as a weighted sum of the temperature, rainfall, and humidity. This equation is an approximation since the actual relationship may not necessarily be linear, and there may be other factors involved. But a simple linear model like this often works well in practice.\n",
    "\n",
    "Based on some statical analysis of historical data, we might come up with reasonable values for the weights `w1`, `w2`, and `w3`. Here's an example set of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JX65ykRJmwJ0"
   },
   "outputs": [],
   "source": [
    "w1, w2, w3 = 0.3, 0.2, 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_o2dzB1mwJ1"
   },
   "source": [
    "Given some climate data for a region, we can now predict the yield of apples. Here's some sample data:\n",
    "\n",
    "<img src=\"https://i.imgur.com/TXPBiqv.png\" style=\"width:360px;\">\n",
    "\n",
    "To begin, we can define some variables to record climate data for a region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcAousDtmwJ2"
   },
   "outputs": [],
   "source": [
    "kanto_temp = 73\n",
    "kanto_rainfall = 67\n",
    "kanto_humidity = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuwxxDB8mwJ3"
   },
   "source": [
    "We can now substitute these variables into the linear equation to predict the yield of apples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wizef9VCmwJ3"
   },
   "outputs": [],
   "source": [
    "kanto_yield_apples = kanto_temp * w1 + kanto_rainfall * w2 + kanto_humidity * w3\n",
    "kanto_yield_apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iciLwsoAmwJ4"
   },
   "outputs": [],
   "source": [
    "print(\"The expected yield of apples in Kanto region is {} tons per hectare.\".format(kanto_yield_apples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2hYYAwTmwJ5"
   },
   "source": [
    "To make it slightly easier to perform the above computation for multiple regions, we can represent the climate data for each region as a vector, i.e., a list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_3oGn1xYmwJ5"
   },
   "outputs": [],
   "source": [
    "kanto = [73, 67, 43]\n",
    "johto = [91, 88, 64]\n",
    "hoenn = [87, 134, 58]\n",
    "sinnoh = [102, 43, 37]\n",
    "unova = [69, 96, 70]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHzn3HkcmwJ6"
   },
   "source": [
    "The three numbers in each vector represent the temperature, rainfall, and humidity data, respectively. \n",
    "\n",
    "We can also represent the set of weights used in the formula as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgFNX3jZmwJ6"
   },
   "outputs": [],
   "source": [
    "weights = [w1, w2, w3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhTPSjC5mwJ6"
   },
   "source": [
    "We can now write a function `crop_yield` to calcuate the yield of apples (or any other crop) given the climate data and the respective weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O42_tQKmmwJ7"
   },
   "outputs": [],
   "source": [
    "def crop_yield(region, weights):\n",
    "    result = 0\n",
    "    for x, w in zip(region, weights):\n",
    "        result += x * w\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oq2NNw30mwJ7"
   },
   "outputs": [],
   "source": [
    "crop_yield(kanto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vVtedmHzmwJ7"
   },
   "outputs": [],
   "source": [
    "crop_yield(johto, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BnjyF1s9mwJ8"
   },
   "outputs": [],
   "source": [
    "crop_yield(unova, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yI2wGITymwJ8"
   },
   "source": [
    "## Going from Python lists to Numpy arrays\n",
    "\n",
    "\n",
    "The calculation performed by the `crop_yield` (element-wise multiplication of two vectors and taking a sum of the results) is also called the *dot product*. Learn more about dot product here: https://www.khanacademy.org/math/linear-algebra/vectors-and-spaces/dot-cross-products/v/vector-dot-product-and-vector-length . \n",
    "\n",
    "The Numpy library provides a built-in function to compute the dot product of two vectors. However, we must first convert the lists into Numpy arrays.\n",
    "\n",
    "Let's install the Numpy library using the `pip` package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwFSke0omwJ9"
   },
   "outputs": [],
   "source": [
    "!pip install numpy --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wncMNa85mwJ9"
   },
   "source": [
    "Next, let's import the `numpy` module. It's common practice to import numpy with the alias `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p78SzRgmmwJ9"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1KVASYrEmwJ9"
   },
   "source": [
    "We can now use the `np.array` function to create Numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFZaSzM4mwJ-"
   },
   "outputs": [],
   "source": [
    "kanto = np.array([73, 67, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc5KYQVWmwJ-"
   },
   "outputs": [],
   "source": [
    "kanto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZfyxJfcmwJ-"
   },
   "outputs": [],
   "source": [
    "weights = np.array([w1, w2, w3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZxYIFDsmwJ-"
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePkeEwhVmwJ-"
   },
   "source": [
    "Numpy arrays have the type `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "THumz8LkmwJ_"
   },
   "outputs": [],
   "source": [
    "type(kanto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSQZ517hmwJ_"
   },
   "outputs": [],
   "source": [
    "type(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_rUEtyFmwJ_"
   },
   "source": [
    "Just like lists, Numpy arrays support the indexing notation `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qb4nAt48mwJ_"
   },
   "outputs": [],
   "source": [
    "weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNi0j2yVmwKA"
   },
   "outputs": [],
   "source": [
    "kanto[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MATFZjsumwKA"
   },
   "source": [
    "## Operating on Numpy arrays\n",
    "\n",
    "We can now compute the dot product of the two vectors using the `np.dot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6beZBj51mwKA"
   },
   "outputs": [],
   "source": [
    "np.dot(kanto, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdguoXPGmwKA"
   },
   "source": [
    "We can achieve the same result with low-level operations supported by Numpy arrays: performing an element-wise multiplication and calculating the resulting numbers' sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1msNv0uAmwKA"
   },
   "outputs": [],
   "source": [
    "(kanto * weights).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uULUGXi5mwKB"
   },
   "source": [
    "The `*` operator performs an element-wise multiplication of two arrays if they have the same size. The `sum` method calculates the sum of numbers in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cVxNPIOomwKB"
   },
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "arr2 = np.array([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kh5YPVU6mwKB"
   },
   "outputs": [],
   "source": [
    "arr1 * arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VDF3bI5mwKB"
   },
   "outputs": [],
   "source": [
    "arr2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHwJ6QGImwKB"
   },
   "source": [
    "## Benefits of using Numpy arrays\n",
    "\n",
    "Numpy arrays offer the following benefits over Python lists for operating on numerical data:\n",
    "\n",
    "- **Ease of use**: You can write small, concise, and intuitive mathematical expressions like `(kanto * weights).sum()` rather than using loops & custom functions like `crop_yield`.\n",
    "- **Performance**: Numpy operations and functions are implemented internally in C++, which makes them much faster than using Python statements & loops that are interpreted at runtime\n",
    "\n",
    "Here's a comparison of dot products performed using Python loops vs. Numpy arrays on two vectors with a million elements each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaxsY8VsmwKC"
   },
   "outputs": [],
   "source": [
    "# Python lists\n",
    "arr1 = list(range(1000000))\n",
    "arr2 = list(range(1000000, 2000000))\n",
    "\n",
    "# Numpy arrays\n",
    "arr1_np = np.array(arr1)\n",
    "arr2_np = np.array(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bILQclxamwKC"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = 0\n",
    "for x1, x2 in zip(arr1, arr2):\n",
    "    result += x1*x2\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL-4_bcHmwKC"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "np.dot(arr1_np, arr2_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UI1xcJC6mwKC"
   },
   "source": [
    "As you can see, using `np.dot` is 100 times faster than using a `for` loop. This makes Numpy especially useful while working with really large datasets with tens of thousands or millions of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0GZyvHvmwKD"
   },
   "source": [
    "## Multi-dimensional Numpy arrays \n",
    "\n",
    "We can now go one step further and represent the climate data for all the regions using a single 2-dimensional Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sbv3YlpmwKD"
   },
   "outputs": [],
   "source": [
    "climate_data = np.array([[73, 67, 43],\n",
    "                         [91, 88, 64],\n",
    "                         [87, 134, 58],\n",
    "                         [102, 43, 37],\n",
    "                         [69, 96, 70]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rpBFnvWPmwKD"
   },
   "outputs": [],
   "source": [
    "climate_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avuL4Bu5mwKD"
   },
   "source": [
    "If you've taken a linear algebra class in high school, you may recognize the above 2-d array as a matrix with five rows and three columns. Each row represents one region, and the columns represent temperature, rainfall, and humidity, respectively.\n",
    "\n",
    "Numpy arrays can have any number of dimensions and different lengths along each dimension. We can inspect the length along each dimension using the `.shape` property of an array.\n",
    "\n",
    "<img src=\"https://fgnt.github.io/python_crashkurs_doc/_images/numpy_array_t.png\" width=\"420\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxPh6FK5mwKD"
   },
   "outputs": [],
   "source": [
    "# 2D array (matrix)\n",
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xo-tWF6XmwKD"
   },
   "outputs": [],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YsnNPdylmwKE"
   },
   "outputs": [],
   "source": [
    "# 1D array (vector)\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFA0BquimwKE"
   },
   "outputs": [],
   "source": [
    "# 3D array \n",
    "arr3 = np.array([\n",
    "    [[11, 12, 13], \n",
    "     [13, 14, 15]], \n",
    "    [[15, 16, 17], \n",
    "     [17, 18, 19.5]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OELnH3ZQmwKE"
   },
   "outputs": [],
   "source": [
    "arr3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9K6IxO7LmwKE"
   },
   "source": [
    "All the elements in a numpy array have the same data type. You can check the data type of an array using the `.dtype` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mt4oNCbFmwKE"
   },
   "outputs": [],
   "source": [
    "weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AFHhTcumwKE"
   },
   "outputs": [],
   "source": [
    "climate_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzN2V4MEmwKF"
   },
   "source": [
    "If an array contains even a single floating point number, all the other elements are also converted to floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmUzQGugmwKF"
   },
   "outputs": [],
   "source": [
    "arr3.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kKzFnikmwKF"
   },
   "source": [
    "We can now compute the predicted yields of apples in all the regions, using a single matrix multiplication between `climate_data` (a 5x3 matrix) and `weights` (a vector of length 3). Here's what it looks like visually:\n",
    "\n",
    "<img src=\"https://i.imgur.com/LJ2WKSI.png\" width=\"240\">\n",
    "\n",
    "You can learn about matrices and matrix multiplication by watching the first 3-4 videos of this playlist: https://www.youtube.com/watch?v=xyAuNHPsq-g&list=PLFD0EB975BA0CC1E0&index=1 .\n",
    "\n",
    "We can use the `np.matmul` function or the `@` operator to perform matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nllxOY7NmwKF"
   },
   "outputs": [],
   "source": [
    "np.matmul(climate_data, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UOxmfMVFmwKF"
   },
   "outputs": [],
   "source": [
    "climate_data @ weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvpBC0N6mwKF"
   },
   "source": [
    "## Working with CSV data files\n",
    "\n",
    "Numpy also provides helper functions reading from & writing to files. `climate.txt` contains 10,000 climate measurements (temperature, rainfall & humidity) in the following format:\n",
    "\n",
    "\n",
    "```\n",
    "temperature,rainfall,humidity\n",
    "25.00,76.00,99.00\n",
    "39.00,65.00,70.00\n",
    "59.00,45.00,77.00\n",
    "84.00,63.00,38.00\n",
    "66.00,50.00,52.00\n",
    "41.00,94.00,77.00\n",
    "91.00,57.00,96.00\n",
    "49.00,96.00,99.00\n",
    "67.00,20.00,28.00\n",
    "...\n",
    "```\n",
    "\n",
    "This format of storing data is known as *comma-separated values* or CSV. \n",
    "\n",
    "> **CSVs**: A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields. (Wikipedia)\n",
    "\n",
    "\n",
    "To read this file into a numpy array, we can use the `genfromtxt` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8rldi4WmwKG"
   },
   "outputs": [],
   "source": [
    "climate_data = np.genfromtxt('climate.txt', delimiter=',', skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gLmWMYl9mwKG"
   },
   "outputs": [],
   "source": [
    "climate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnM_N9q4mwKG"
   },
   "outputs": [],
   "source": [
    "climate_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luDwllvvmwKG"
   },
   "source": [
    "We can now perform a matrix multiplication using the `@` operator to predict the yield of apples for the entire dataset using a given set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfFkHxgnmwKG"
   },
   "outputs": [],
   "source": [
    "weights = np.array([0.3, 0.2, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Do3oAi_CmwKG"
   },
   "outputs": [],
   "source": [
    "yields = climate_data @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byy-3XUSmwKH"
   },
   "outputs": [],
   "source": [
    "yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cj87MSVWmwKH"
   },
   "outputs": [],
   "source": [
    "yields.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqMHsL1lmwKH"
   },
   "source": [
    "Let's add the `yields` to `climate_data` as a fourth column using the [`np.concatenate`](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "og_GGCBzmwKH"
   },
   "outputs": [],
   "source": [
    "climate_results = np.concatenate((climate_data, yields.reshape(10000, 1)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBdeCITamwKH"
   },
   "outputs": [],
   "source": [
    "climate_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyLkpCyKmwKH"
   },
   "source": [
    "There are a couple of subtleties here:\n",
    "\n",
    "* Since we wish to add new columns, we pass the argument `axis=1` to `np.concatenate`. The `axis` argument specifies the dimension for concatenation.\n",
    "\n",
    "*  The arrays should have the same number of dimensions, and the same length along each except the dimension used for concatenation. We use the [`np.reshape`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) function to change the shape of `yields` from `(10000,)` to `(10000,1)`.\n",
    "\n",
    "Here's a visual explanation of `np.concatenate` along `axis=1` (can you guess what `axis=0` results in?):\n",
    "\n",
    "<img src=\"https://www.w3resource.com/w3r_images/python-numpy-image-exercise-58.png\" width=\"300\">\n",
    "\n",
    "The best way to understand what a Numpy function does is to experiment with it and read the documentation to learn about its arguments & return values. Use the cells below to experiment with `np.concatenate` and `np.reshape`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg8udmWxmwKI"
   },
   "source": [
    "Let's write the final results from our computation above back to a file using the `np.savetxt` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab3jeiE_mwKI"
   },
   "outputs": [],
   "source": [
    "climate_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olvn30MimwKI"
   },
   "outputs": [],
   "source": [
    "np.savetxt('climate_results.txt', \n",
    "           climate_results, \n",
    "           fmt='%.2f', \n",
    "           delimiter=',',\n",
    "           header='temperature,rainfall,humidity,yeild_apples', \n",
    "           comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LzH7ndn6mwKI"
   },
   "source": [
    "The results are written back in the CSV format to the file `climate_results.txt`. \n",
    "\n",
    "```\n",
    "temperature,rainfall,humidity,yeild_apples\n",
    "25.00,76.00,99.00,72.20\n",
    "39.00,65.00,70.00,59.70\n",
    "59.00,45.00,77.00,65.20\n",
    "84.00,63.00,38.00,56.80\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0s6bWZ1mwKI"
   },
   "source": [
    "Numpy provides hundreds of functions for performing operations on arrays. Here are some commonly used functions:\n",
    "\n",
    "\n",
    "* Mathematics: `np.sum`, `np.exp`, `np.round`, arithemtic operators \n",
    "* Array manipulation: `np.reshape`, `np.stack`, `np.concatenate`, `np.split`\n",
    "* Linear Algebra: `np.matmul`, `np.dot`, `np.transpose`, `np.eigvals`\n",
    "* Statistics: `np.mean`, `np.median`, `np.std`, `np.max`\n",
    "\n",
    "> **How to find the function you need?** The easiest way to find the right function for a specific operation or use-case is to do a web search. For instance, searching for \"How to join numpy arrays\" leads to [this tutorial on array concatenation](https://cmdlinetips.com/2018/04/how-to-concatenate-arrays-in-numpy/). \n",
    "\n",
    "You can find a full list of array functions here: https://numpy.org/doc/stable/reference/routines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lm8J2z6JmwKJ"
   },
   "source": [
    "## Arithmetic operations, broadcasting and comparison\n",
    "\n",
    "Numpy arrays support arithmetic operators like `+`, `-`, `*`, etc. You can perform an arithmetic operation with a single number (also called scalar) or with another array of the same shape. Operators make it easy to write mathematical expressions with multi-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48xjW45wmwKJ"
   },
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3, 4], \n",
    "                 [5, 6, 7, 8], \n",
    "                 [9, 1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MN6enYNjmwKJ"
   },
   "outputs": [],
   "source": [
    "arr3 = np.array([[11, 12, 13, 14], \n",
    "                 [15, 16, 17, 18], \n",
    "                 [19, 11, 12, 13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDQ9P4EhmwKK"
   },
   "outputs": [],
   "source": [
    "# Adding a scalar\n",
    "arr2 + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QKdTvfi7mwKK"
   },
   "outputs": [],
   "source": [
    "# Element-wise subtraction\n",
    "arr3 - arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7PetWRUmwKK"
   },
   "outputs": [],
   "source": [
    "# Division by scalar\n",
    "arr2 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-OiJpTRmwKK"
   },
   "outputs": [],
   "source": [
    "# Element-wise multiplication\n",
    "arr2 * arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35eLmeRwmwKK"
   },
   "outputs": [],
   "source": [
    "# Modulus with scalar\n",
    "arr2 % 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNZHjt0kmwKK"
   },
   "source": [
    "### Array Broadcasting\n",
    "\n",
    "Numpy arrays also support *broadcasting*, allowing arithmetic operations between two arrays with different numbers of dimensions but compatible shapes. Let's look at an example to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UvZi9IXOmwKK"
   },
   "outputs": [],
   "source": [
    "arr2 = np.array([[1, 2, 3, 4], \n",
    "                 [5, 6, 7, 8], \n",
    "                 [9, 1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ffdt5uftmwKL"
   },
   "outputs": [],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iH9wpInDmwKL"
   },
   "outputs": [],
   "source": [
    "arr4 = np.array([4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzfUCh_BmwKL"
   },
   "outputs": [],
   "source": [
    "arr4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AdnKsZ_mwKL"
   },
   "outputs": [],
   "source": [
    "arr2 + arr4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovbqEh4jmwKL"
   },
   "source": [
    "When the expression `arr2 + arr4` is evaluated, `arr4` (which has the shape `(4,)`) is replicated three times to match the shape `(3, 4)` of `arr2`. Numpy performs the replication without actually creating three copies of the smaller dimension array, thus improving performance and using lower memory.\n",
    "\n",
    "<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/02.05-broadcasting.png\" width=\"360\">\n",
    "\n",
    "Broadcasting only works if one of the arrays can be replicated to match the other array's shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTf2xGkSmwKM"
   },
   "outputs": [],
   "source": [
    "arr5 = np.array([7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDsXc-p2mwKM"
   },
   "outputs": [],
   "source": [
    "arr5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijuQ01RImwKM"
   },
   "outputs": [],
   "source": [
    "arr2 + arr5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEt-Nug2mwKM"
   },
   "source": [
    "In the above example, even if `arr5` is replicated three times, it will not match the shape of `arr2`. Hence `arr2 + arr5` cannot be evaluated successfully. Learn more about broadcasting here: https://numpy.org/doc/stable/user/basics.broadcasting.html ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exLSopeTmwKN"
   },
   "source": [
    "### Array Comparison\n",
    "\n",
    "Numpy arrays also support comparison operations like `==`, `!=`, `>` etc. The result is an array of booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygjvUrDDmwKN"
   },
   "outputs": [],
   "source": [
    "arr1 = np.array([[1, 2, 3], [3, 4, 5]])\n",
    "arr2 = np.array([[2, 2, 3], [1, 2, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EpHoPE0xmwKN"
   },
   "outputs": [],
   "source": [
    "arr1 == arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2seG0RvkmwKN"
   },
   "outputs": [],
   "source": [
    "arr1 != arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FMl_GRKmwKN"
   },
   "outputs": [],
   "source": [
    "arr1 >= arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRTsGlRrmwKN"
   },
   "outputs": [],
   "source": [
    "arr1 < arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdLMMTWOmwKO"
   },
   "source": [
    "Array comparison is frequently used to count the number of equal elements in two arrays using the `sum` method. Remember that `True` evaluates to `1` and `False` evaluates to `0` when booleans are used in arithmetic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfTJZzt2mwKO"
   },
   "outputs": [],
   "source": [
    "(arr1 == arr2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHDQN9aHmwKO"
   },
   "source": [
    "## Array indexing and slicing\n",
    "\n",
    "Numpy extends Python's list indexing notation using `[]` to multiple dimensions in an intuitive fashion. You can provide a comma-separated list of indices or ranges to select a specific element or a subarray (also called a slice) from a Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHM4Q5gcmwKO"
   },
   "outputs": [],
   "source": [
    "arr3 = np.array([\n",
    "    [[11, 12, 13, 14], \n",
    "     [13, 14, 15, 19]], \n",
    "    \n",
    "    [[15, 16, 17, 21], \n",
    "     [63, 92, 36, 18]], \n",
    "    \n",
    "    [[98, 32, 81, 23],      \n",
    "     [17, 18, 19.5, 43]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpPVUBlxmwKO"
   },
   "outputs": [],
   "source": [
    "arr3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_30c3GhEmwKO"
   },
   "outputs": [],
   "source": [
    "# Single element\n",
    "arr3[1, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hofoAx5BmwKO"
   },
   "outputs": [],
   "source": [
    "# Subarray using ranges\n",
    "arr3[1:, 0:1, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRYO4sHXmwKP"
   },
   "outputs": [],
   "source": [
    "# Mixing indices and ranges\n",
    "arr3[1:, 1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUeKAAzEmwKP"
   },
   "outputs": [],
   "source": [
    "# Mixing indices and ranges\n",
    "arr3[1:, 1, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5tnfY6tmwKP"
   },
   "outputs": [],
   "source": [
    "# Using fewer indices\n",
    "arr3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEZn8b33mwKP"
   },
   "outputs": [],
   "source": [
    "# Using fewer indices\n",
    "arr3[:2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIkpGFXPvxnH"
   },
   "source": [
    "However, we cannot use too many indices like `arr3[1,3,2,1]`. This will give us `IndexError: too many indices for array: array is 3-dimensional, but 4 were indexed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cdf8f8ammwKQ"
   },
   "source": [
    "The notation and its results can seem confusing at first, so take your time to experiment and become comfortable with it. Use the cells below to try out some examples of array indexing and slicing, with different combinations of indices and ranges. Here are some more examples demonstrated visually:\n",
    "\n",
    "<img src=\"https://scipy-lectures.org/_images/numpy_indexing.png\" width=\"360\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqDo30yhmwKQ"
   },
   "source": [
    "## Other ways of creating Numpy arrays\n",
    "\n",
    "Numpy also provides some handy functions to create arrays of desired shapes with fixed or random values. Check out the [official documentation](https://numpy.org/doc/stable/reference/routines.array-creation.html) or use the `help` function to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B9Ppr8CsmwKQ"
   },
   "outputs": [],
   "source": [
    "# All zeros\n",
    "np.zeros((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcQG07ufmwKR"
   },
   "outputs": [],
   "source": [
    "# All ones\n",
    "np.ones([2, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vg5FgE0smwKR"
   },
   "outputs": [],
   "source": [
    "# Identity matrix\n",
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XXrfAVKVmwKR"
   },
   "outputs": [],
   "source": [
    "# Random vector\n",
    "np.random.rand(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FnFxiOgmwKR"
   },
   "outputs": [],
   "source": [
    "# Random matrix\n",
    "np.random.randn(2, 3) # rand vs. randn - what's the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SN_eni3amwKR"
   },
   "outputs": [],
   "source": [
    "# Fixed value\n",
    "np.full([2, 3], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6guMxw3nmwKR"
   },
   "outputs": [],
   "source": [
    "# Range with start, end and step\n",
    "np.arange(10, 90, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fv-KVN-2mwKS"
   },
   "outputs": [],
   "source": [
    "# Equally spaced numbers in a range\n",
    "np.linspace(3, 27, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rD5Dg3uWS7bn"
   },
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S8hr9xNtTKi8"
   },
   "source": [
    "**Q1: Write a NumPy program to compute the covariance matrix of two given arrays.**\n",
    "\n",
    "Example:\n",
    "\n",
    "Original array1:\n",
    "``[0 1 2]``\n",
    "\n",
    "Original array2:\n",
    "``[2 1 0]``\n",
    "\n",
    "Covariance matrix of the said arrays:\n",
    "```python\n",
    "[[ 1. -1.]\n",
    "[-1. 1.]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tuIwBdOUR23"
   },
   "outputs": [],
   "source": [
    "x = np.array([0, 1, 2])\n",
    "y = np.array([2, 1, 0])\n",
    "# ENTER CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sgG9kW5SWzr3"
   },
   "source": [
    "**Q2: Write a NumPy program to get the minimum and maximum value of a given array along the second axis.**\n",
    "\n",
    "Example:\n",
    "\n",
    "Original array:\n",
    "```python \n",
    "[[0 1]\n",
    "[2 3]]\n",
    "```\n",
    "Maximum value along the second axis:\n",
    "``[1 3]``\n",
    "Minimum value along the second axis:\n",
    "``[0 2]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYkqaidLWzbo"
   },
   "outputs": [],
   "source": [
    "x = np.arange(4).reshape((2, 2))\n",
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKZwsrf4Uo_9"
   },
   "source": [
    "**Q3: Write a Python program to count number of occurrences of each value in a given array of non-negative integers**\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "Original array:\n",
    "``[0, 1, 6, 1, 4, 1, 2, 2, 7]``\n",
    "\n",
    "Number of occurrences of each value in array:\n",
    "``[1 3 2 0 1 0 1 1]``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_Gv5EUPUqax"
   },
   "outputs": [],
   "source": [
    "array1 = [0, 1, 6, 1, 4, 1, 2, 2, 7] \n",
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gh1hTQpZaW8l"
   },
   "source": [
    "**Q4: Compute the min-by-max for each row for given 2d numpy array.**\n",
    "\n",
    "Example:\n",
    "\n",
    "Original array:\n",
    "```python\n",
    "[[9 9 4]\n",
    " [8 8 1]\n",
    " [5 3 6]\n",
    " [3 3 3]\n",
    " [2 1 9]]\n",
    " ```\n",
    "\n",
    "Output:\n",
    "\n",
    "`[ 0.44444444,  0.125     ,  0.5       ,  1.        ,  0.11111111]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwCoFA1oaXpu"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "a = np.random.randint(1,10, [5,3])\n",
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eoc-P8-RmwKS"
   },
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "With this, we complete our discussion of numerical computing with Numpy. We've covered the following topics in this tutorial:\n",
    "\n",
    "- Going from Python lists to Numpy arrays\n",
    "- Operating on Numpy arrays\n",
    "- Benefits of using Numpy arrays over lists\n",
    "- Multi-dimensional Numpy arrays\n",
    "- Working with CSV data files\n",
    "- Arithmetic operations and broadcasting\n",
    "- Array indexing and slicing\n",
    "- Other ways of creating Numpy arrays\n",
    "\n",
    "\n",
    "Check out the following resources for learning more about Numpy:\n",
    "\n",
    "- Official tutorial: https://numpy.org/devdocs/user/quickstart.html\n",
    "- Numpy tutorial on W3Schools: https://www.w3schools.com/python/numpy_intro.asp\n",
    "- Advanced Numpy (exploring the internals): http://scipy-lectures.org/advanced/advanced_numpy/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcCRx4a7zZvi"
   },
   "source": [
    "#Pandas Basics\n",
    "![](https://i.imgur.com/zfxLzEv.png)\n",
    "This tutorial covers the following topics:\n",
    "\n",
    "- Reading a CSV file into a Pandas data frame\n",
    "- Retrieving data from Pandas data frames\n",
    "- Querying, soring, and analyzing data\n",
    "- Basic plotting using line and bar charts\n",
    "- Writing data frames to CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-7Aa58PzZvl"
   },
   "source": [
    "## Reading a CSV file using Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a popular Python library used for working in tabular data (similar to the data stored in a spreadsheet). Pandas provides helper functions to read data from various file formats like CSV, Excel spreadsheets, HTML tables, JSON, SQL, and more. In this exercise we will work on `italy-covid-daywise.txt` file which contains day-wise Covid-19 data for Italy in the following format:\n",
    "\n",
    "```\n",
    "date,new_cases,new_deaths,new_tests\n",
    "2020-04-21,2256.0,454.0,28095.0\n",
    "2020-04-22,2729.0,534.0,44248.0\n",
    "2020-04-23,3370.0,437.0,37083.0\n",
    "2020-04-24,2646.0,464.0,95273.0\n",
    "2020-04-25,3021.0,420.0,38676.0\n",
    "2020-04-26,2357.0,415.0,24113.0\n",
    "2020-04-27,2324.0,260.0,26678.0\n",
    "2020-04-28,1739.0,333.0,37554.0\n",
    "...\n",
    "```\n",
    "\n",
    "This format of storing data is known as *comma-separated values* or CSV. \n",
    "\n",
    "> **CSVs**: A comma-separated values (CSV) file is a delimited text file that uses a comma to separate values. Each line of the file is a data record. Each record consists of one or more fields, separated by commas. A CSV file typically stores tabular data (numbers and text) in plain text, in which case each line will have the same number of fields. (Wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjyYUrpQzZvm"
   },
   "outputs": [],
   "source": [
    "#restart the kernel after installation\n",
    "!pip install pandas-profiling --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doMHx0HczZvr"
   },
   "source": [
    "To read the file, we can use the `read_csv` method from Pandas. First, let's install the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ST981ZgZzZvs"
   },
   "source": [
    "We can now import the `pandas` module. As a convention, it is imported with the alias `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LaORwwuWzZvt"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hoMZi9XzZvu"
   },
   "outputs": [],
   "source": [
    "covid_df = pd.read_csv('italy-covid-daywise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugocOTutzZvv"
   },
   "source": [
    "Data from the file is read and stored in a `DataFrame` object - one of the core data structures in Pandas for storing and working with tabular data. We typically use the `_df` suffix in the variable names for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4s_o_omSzZvw"
   },
   "outputs": [],
   "source": [
    "type(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q29hFdvzZvw"
   },
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OjEEyZMzZvx"
   },
   "source": [
    "Here's what we can tell by looking at the dataframe:\n",
    "\n",
    "- The file provides four day-wise counts for COVID-19 in Italy\n",
    "- The metrics reported are new cases, deaths, and tests\n",
    "- Data is provided for 248 days: from Dec 12, 2019, to Sep 3, 2020\n",
    "\n",
    "Keep in mind that these are officially reported numbers. The actual number of cases & deaths may be higher, as not all cases are diagnosed. \n",
    "\n",
    "We can view some basic information about the data frame using the `.info` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dIt9nZ3zZvx"
   },
   "outputs": [],
   "source": [
    "covid_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeQ2gI7UzZvy"
   },
   "source": [
    "It appears that each column contains values of a specific data type. You can view statistical information for numerical columns (mean, standard deviation, minimum/maximum values, and the number of non-empty values) using the `.describe` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aeGXxSSzZvy"
   },
   "outputs": [],
   "source": [
    "covid_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ccc-W6IzZvz"
   },
   "source": [
    "The `columns` property contains the list of columns within the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9A3NLbszZv0"
   },
   "outputs": [],
   "source": [
    "covid_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCJ6DOxtzZv1"
   },
   "source": [
    "You can also retrieve the number of rows and columns in the data frame using the `.shape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRydIJBbzZv1"
   },
   "outputs": [],
   "source": [
    "covid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zc2X2VQ5zZv2"
   },
   "source": [
    "Here's a summary of the functions & methods we've looked at so far:\n",
    "\n",
    "* `pd.read_csv` - Read data from a CSV file into a Pandas `DataFrame` object\n",
    "* `.info()` - View basic infomation about rows, columns & data types\n",
    "* `.describe()` - View statistical information about numeric columns\n",
    "* `.columns` - Get the list of column names\n",
    "* `.shape` - Get the number of rows & columns as a tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alXg8L55zZv4"
   },
   "source": [
    "## Retrieving data from a data frame\n",
    "\n",
    "The first thing you might want to do is retrieve data from this data frame, e.g., the counts of a specific day or the list of values in a particular column. To do this, it might help to understand the internal representation of data in a data frame. Conceptually, you can think of a dataframe as a dictionary of lists: keys are column names, and values are lists/arrays containing data for the respective columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8mWlvVBzZv5"
   },
   "outputs": [],
   "source": [
    "# Pandas format is simliar to this\n",
    "covid_data_dict = {\n",
    "    'date':       ['2020-08-30', '2020-08-31', '2020-09-01', '2020-09-02', '2020-09-03'],\n",
    "    'new_cases':  [1444, 1365, 996, 975, 1326],\n",
    "    'new_deaths': [1, 4, 6, 8, 6],\n",
    "    'new_tests': [53541, 42583, 54395, None, None]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIYSvNRbzZv5"
   },
   "source": [
    "Representing data in the above format has a few benefits:\n",
    "\n",
    "* All values in a column typically have the same type of value, so it's more efficient to store them in a single array.\n",
    "* Retrieving the values for a particular row simply requires extracting the elements at a given index from each column array.\n",
    "* The representation is more compact (column names are recorded only once) compared to other formats that use a dictionary for each row of data (see the example below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpSoeqVVzZv5"
   },
   "outputs": [],
   "source": [
    "# Pandas format is not similar to this\n",
    "covid_data_list = [\n",
    "    {'date': '2020-08-30', 'new_cases': 1444, 'new_deaths': 1, 'new_tests': 53541},\n",
    "    {'date': '2020-08-31', 'new_cases': 1365, 'new_deaths': 4, 'new_tests': 42583},\n",
    "    {'date': '2020-09-01', 'new_cases': 996, 'new_deaths': 6, 'new_tests': 54395},\n",
    "    {'date': '2020-09-02', 'new_cases': 975, 'new_deaths': 8 },\n",
    "    {'date': '2020-09-03', 'new_cases': 1326, 'new_deaths': 6},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiEqmaLLzZv5"
   },
   "source": [
    "With the dictionary of lists analogy in mind, you can now guess how to retrieve data from a data frame. For example, we can get a list of values from a specific column using the `[]` indexing notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lbky-cq8zZv6"
   },
   "outputs": [],
   "source": [
    "covid_data_dict['new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WW7YFPezZv6"
   },
   "outputs": [],
   "source": [
    "covid_df['new_cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1K1iO0aJzZv6"
   },
   "source": [
    "Each column is represented using a data structure called `Series`, which is essentially a numpy array with some extra methods and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfe8rCD1zZv7"
   },
   "outputs": [],
   "source": [
    "type(covid_df['new_cases'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DwWJ28azZv7"
   },
   "source": [
    "Like arrays, you can retrieve a specific value with a series using the indexing notation `[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QLwb2YH2zZv8"
   },
   "outputs": [],
   "source": [
    "covid_df['new_cases'][246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GuNFRGTWzZv8"
   },
   "outputs": [],
   "source": [
    "covid_df['new_tests'][240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vbnU7wKVzZv9"
   },
   "source": [
    "Pandas also provides the `.at` method to retrieve the element at a specific row & column directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MzT2wkIrzZv9"
   },
   "outputs": [],
   "source": [
    "covid_df.at[246, 'new_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "octloKpbzZv-"
   },
   "outputs": [],
   "source": [
    "covid_df.at[240, 'new_tests']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTOWOturzZv-"
   },
   "source": [
    "Instead of using the indexing notation `[]`, Pandas also allows accessing columns as properties of the dataframe using the `.` notation. However, this method only works for columns whose names do not contain spaces or special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EGZyGF5xzZv-"
   },
   "outputs": [],
   "source": [
    "covid_df.new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS_3TczezZv_"
   },
   "source": [
    "Further, you can also pass a list of columns within the indexing notation `[]` to access a subset of the data frame with just the given columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAC0K7VZzZv_"
   },
   "outputs": [],
   "source": [
    "cases_df = covid_df[['date', 'new_cases']]\n",
    "cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-ktPRXjzZv_"
   },
   "source": [
    "The new data frame `cases_df` is simply a \"view\" of the original data frame `covid_df`. Both point to the same data in the computer's memory. Changing any values inside one of them will also change the respective values in the other. Sharing data between data frames makes data manipulation in Pandas blazing fast. You needn't worry about the overhead of copying thousands or millions of rows every time you want to create a new data frame by operating on an existing one.\n",
    "\n",
    "Sometimes you might need a full copy of the data frame, in which case you can use the `copy` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSH86fgFzZwA"
   },
   "outputs": [],
   "source": [
    "covid_df_copy = covid_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIg309gazZwA"
   },
   "source": [
    "The data within `covid_df_copy` is completely separate from `covid_df`, and changing values inside one of them will not affect the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOf_o6I2zZwB"
   },
   "source": [
    "To access a specific row of data, Pandas provides the `.loc` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uaoo4jrUzZwB"
   },
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IiS0y30OzZwB"
   },
   "outputs": [],
   "source": [
    "covid_df.loc[243]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvllXVRYzZwC"
   },
   "source": [
    "Each retrieved row is also a `Series` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ll8-Iu3LzZwC"
   },
   "outputs": [],
   "source": [
    "type(covid_df.loc[243])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlzfqsgRzZwD"
   },
   "source": [
    "We can use the `.head` and `.tail` methods to view the first or last few rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eCoILgIzZwD"
   },
   "outputs": [],
   "source": [
    "covid_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnVf8tz5zZwE"
   },
   "outputs": [],
   "source": [
    "covid_df.tail(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fN_VJgezZwE"
   },
   "source": [
    "Notice above that while the first few values in the `new_cases` and `new_deaths` columns are `0`, the corresponding values within the `new_tests` column are `NaN`. That is because the CSV file does not contain any data for the `new_tests` column for specific dates (you can verify this by looking into the file). These values may be missing or unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "elbChVV5zZwF"
   },
   "outputs": [],
   "source": [
    "covid_df.at[0, 'new_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Riu5z9wzZwF"
   },
   "outputs": [],
   "source": [
    "type(covid_df.at[0, 'new_tests'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDxSVOb6zZwG"
   },
   "source": [
    "The distinction between `0` and `NaN` is subtle but important. In this dataset, it represents that daily test numbers were not reported on specific dates. Italy started reporting daily tests on Apr 19, 2020. 93,5310 tests had already been conducted before Apr 19. \n",
    "\n",
    "We can find the first index that doesn't contain a `NaN` value using a column's `first_valid_index` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i35RcYrQzZwG"
   },
   "outputs": [],
   "source": [
    "covid_df.new_tests.first_valid_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmcPEfbZzZwH"
   },
   "source": [
    "Let's look at a few rows before and after this index to verify that the values change from `NaN` to actual numbers. We can do this by passing a range to `loc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35jZtgJBzZwH"
   },
   "outputs": [],
   "source": [
    "covid_df.loc[108:113]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26tmaiA5zZwH"
   },
   "source": [
    "We can use the `.sample` method to retrieve a random sample of rows from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-FhYlth8zZwH"
   },
   "outputs": [],
   "source": [
    "covid_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OU-7l2brzZwI"
   },
   "source": [
    "Notice that even though we have taken a random sample, each row's original index is preserved - this is a useful property of data frames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bxws0m-9zZwI"
   },
   "source": [
    "Here's a summary of the functions & methods we looked at in this section:\n",
    "\n",
    "- `covid_df['new_cases']` - Retrieving columns as a `Series` using the column name\n",
    "- `new_cases[243]` - Retrieving values from a `Series` using an index\n",
    "- `covid_df.at[243, 'new_cases']` - Retrieving a single value from a data frame\n",
    "- `covid_df.copy()` - Creating a deep copy of a data frame\n",
    "- `covid_df.loc[243]` - Retrieving a row or range of rows of data from the data frame\n",
    "- `head`, `tail`, and `sample` - Retrieving multiple rows of data from the data frame\n",
    "- `covid_df.new_tests.first_valid_index` - Finding the first non-empty index in a series\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akWEhJiuzZwS"
   },
   "source": [
    "## Analyzing data from data frames\n",
    "\n",
    "Let's try to answer some questions about our data.\n",
    "\n",
    "**Q: What are the total number of reported cases and deaths related to Covid-19 in Italy?**\n",
    "\n",
    "Similar to Numpy arrays, a Pandas series supports the `sum` method to answer these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mxhPbJSzZwS"
   },
   "outputs": [],
   "source": [
    "total_cases = covid_df.new_cases.sum()\n",
    "total_deaths = covid_df.new_deaths.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEopFigNzZwT"
   },
   "outputs": [],
   "source": [
    "print('The number of reported cases is {} and the number of reported deaths is {}.'.format(int(total_cases), int(total_deaths)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIrYau3lzZwT"
   },
   "source": [
    "**Q: What is the overall death rate (ratio of reported deaths to reported cases)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HBbTgFmvzZwT"
   },
   "outputs": [],
   "source": [
    "death_rate = covid_df.new_deaths.sum() / covid_df.new_cases.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ou0NmkFDzZwT"
   },
   "outputs": [],
   "source": [
    "print(\"The overall reported death rate in Italy is {:.2f} %.\".format(death_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ds3WpmA-zZwU"
   },
   "source": [
    "**Q: What is the overall number of tests conducted? A total of 935310 tests were conducted before daily test numbers were reported.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ua6_MC7QzZwU"
   },
   "outputs": [],
   "source": [
    "initial_tests = 935310\n",
    "total_tests = initial_tests + covid_df.new_tests.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVRMf89tzZwU"
   },
   "outputs": [],
   "source": [
    "total_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "14nhV3HPzZwV"
   },
   "source": [
    "**Q: What fraction of tests returned a positive result?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKqSQ3lSzZwV"
   },
   "outputs": [],
   "source": [
    "positive_rate = total_cases / total_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4S0Lg9VczZwV"
   },
   "outputs": [],
   "source": [
    "print('{:.2f}% of tests in Italy led to a positive diagnosis.'.format(positive_rate*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTXsX4NpzZwW"
   },
   "source": [
    "## Querying and sorting rows\n",
    "\n",
    "Let's say we want only want to look at the days which had more than 1000 reported cases. We can use a boolean expression to check which rows satisfy this criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uaIOyIPOzZwW"
   },
   "outputs": [],
   "source": [
    "high_new_cases = covid_df.new_cases > 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHSKR1KMzZwW"
   },
   "outputs": [],
   "source": [
    "high_new_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGtmMHT7zZwX"
   },
   "source": [
    "The boolean expression returns a series containing `True` and `False` boolean values. You can use this series to select a subset of rows from the original dataframe, corresponding to the `True` values in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SNxN9iogzZwX"
   },
   "outputs": [],
   "source": [
    "covid_df[high_new_cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Cwcd0WszZwX"
   },
   "source": [
    "We can write this succinctly on a single line by passing the boolean expression as an index to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LI-MreN2zZwX"
   },
   "outputs": [],
   "source": [
    "high_cases_df = covid_df[covid_df.new_cases > 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNM8HsmMzZwX"
   },
   "outputs": [],
   "source": [
    "high_cases_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPjJf2e_zZwX"
   },
   "source": [
    "The data frame contains 72 rows, but only the first & last five rows are displayed by default with Jupyter for brevity. We can change some display options to view all the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRSwJeSyzZwX",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "with pd.option_context('display.max_rows', 100):\n",
    "    display(covid_df[covid_df.new_cases > 1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4aquuSizZwY"
   },
   "source": [
    "We can also formulate more complex queries that involve multiple columns. As an example, let's try to determine the days when the ratio of cases reported to tests conducted is higher than the overall `positive_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a0llJJyHzZwY"
   },
   "outputs": [],
   "source": [
    "positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4pLmtUElzZwY"
   },
   "outputs": [],
   "source": [
    "high_ratio_df = covid_df[covid_df.new_cases / covid_df.new_tests > positive_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IStDvaQ2zZwY"
   },
   "outputs": [],
   "source": [
    "high_ratio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vohjQNhmzZwY"
   },
   "source": [
    "The result of performing an operation on two columns is a new series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hA1qfmj6zZwY"
   },
   "outputs": [],
   "source": [
    "covid_df.new_cases / covid_df.new_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4aFHgzUzZwZ"
   },
   "source": [
    "We can use this series to add a new column to the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5JVNim_zZwZ"
   },
   "outputs": [],
   "source": [
    "covid_df['positive_rate'] = covid_df.new_cases / covid_df.new_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8EsUCxuzZwZ"
   },
   "outputs": [],
   "source": [
    "covid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "od_vlcOAzZwZ"
   },
   "source": [
    "However, keep in mind that sometimes it takes a few days to get the results for a test, so we can't compare the number of new cases with the number of tests conducted on the same day. Any inference based on this `positive_rate` column is likely to be incorrect. It's essential to watch out for such subtle relationships that are often not conveyed within the CSV file and require some external context. It's always a good idea to read through the documentation provided with the dataset or ask for more information.\n",
    "\n",
    "For now, let's remove the `positive_rate` column using the `drop` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SabUWj09zZwZ"
   },
   "outputs": [],
   "source": [
    "covid_df.drop(columns=['positive_rate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fU-t8jbCzZwa"
   },
   "source": [
    "Can you figure the purpose of the `inplace` argument?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mIZyC_fxzZwa"
   },
   "source": [
    "### Sorting rows using column values\n",
    "\n",
    "The rows can also be sorted by a specific column using `.sort_values`. Let's sort to identify the days with the highest number of cases, then chain it with the `head` method to list just the first ten results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqasQkSHzZwa"
   },
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VBbIWjUDzZwa"
   },
   "source": [
    "It looks like the last two weeks of March had the highest number of daily cases. Let's compare this to the days where the highest number of deaths were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1FQnDulzZwa"
   },
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_deaths', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H8rOEa4azZwa"
   },
   "source": [
    "It appears that daily deaths hit a peak just about a week after the peak in daily new cases.\n",
    "\n",
    "Let's also look at the days with the least number of cases. We might expect to see the first few days of the year on this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zYeCC-NzZwb"
   },
   "outputs": [],
   "source": [
    "covid_df.sort_values('new_cases').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifr2raeezZwb"
   },
   "source": [
    "It seems like the count of new cases on Jun 20, 2020, was `-148`, a negative number! Not something we might have expected, but that's the nature of real-world data. It could be a data entry error, or the government may have issued a correction to account for miscounting in the past. Can you dig through news articles online and figure out why the number was negative?\n",
    "\n",
    "Let's look at some days before and after Jun 20, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cRtZnNFzZwb"
   },
   "outputs": [],
   "source": [
    "covid_df.loc[169:175]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6QWy3GizZwb"
   },
   "source": [
    "For now, let's assume this was indeed a data entry error. We can use one of the following approaches for dealing with the missing or faulty value:\n",
    "1. Replace it with `0`.\n",
    "2. Replace it with the average of the entire column\n",
    "3. Replace it with the average of the values on the previous & next date\n",
    "4. Discard the row entirely\n",
    "\n",
    "Which approach you pick requires some context about the data and the problem. In this case, since we are dealing with data ordered by date, we can go ahead with the third approach.\n",
    "\n",
    "You can use the `.at` method to modify a specific value within the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8W3vxr1zzZwb"
   },
   "outputs": [],
   "source": [
    "covid_df.at[172, 'new_cases'] = (covid_df.at[171, 'new_cases'] + covid_df.at[173, 'new_cases'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gus-nbyzZwc"
   },
   "source": [
    "Here's a summary of the functions & methods we looked at in this section:\n",
    "\n",
    "- `covid_df.new_cases.sum()` - Computing the sum of values in a column or series\n",
    "- `covid_df[covid_df.new_cases > 1000]` - Querying a subset of rows satisfying the chosen criteria using boolean expressions\n",
    "- `df['pos_rate'] = df.new_cases/df.new_tests` - Adding new columns by combining data from existing columns\n",
    "- `covid_df.drop('positive_rate')` - Removing one or more columns from the data frame\n",
    "- `sort_values` - Sorting the rows of a data frame using column values\n",
    "- `covid_df.at[172, 'new_cases'] = ...` - Replacing a value within the data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNTYKcZ9zZw2"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "Try the following exercises to become familiar with Pandas dataframe and practice your skills. In this assignment, we're going to analyze an operate on data from a CSV file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3c8g1g6j5kjj"
   },
   "outputs": [],
   "source": [
    "#Load the CSV file in the Pandas data frame\n",
    "countries_df = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzOvfeKK5VAn"
   },
   "source": [
    "**Q1: How many countries does the dataframe contain?**\n",
    "\n",
    "Hint: Use the `.shape` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "53rcRU4E5VAo"
   },
   "outputs": [],
   "source": [
    "num_countries = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45rVPYfT6l0G"
   },
   "outputs": [],
   "source": [
    "print('There are {} countries in the dataset'.format(num_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9bFneJrD5VAp"
   },
   "source": [
    "**Q2: Retrieve a list of continents from the dataframe?**\n",
    "\n",
    "*Hint: Use the `.unique` method of a series.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rlsjRQy5VAp"
   },
   "outputs": [],
   "source": [
    "continents =  # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iF9xI2vs5VAq"
   },
   "outputs": [],
   "source": [
    "continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ttl0zWZ35VAq"
   },
   "source": [
    "**Q3: What is the total population of all the countries listed in this dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SyPyAxWD5VAr"
   },
   "outputs": [],
   "source": [
    "total_population = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-wc98vW5VAr"
   },
   "outputs": [],
   "source": [
    "print('The total population is {}.'.format(int(total_population)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u95RSoug5VAs"
   },
   "outputs": [],
   "source": [
    "jovian.commit(project='pandas-practice-assignment', environment=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lpNQhBS5VAt"
   },
   "source": [
    "**Q4: Create a dataframe containing 10 countries with the highest population.**\n",
    "\n",
    "*Hint: Chain the `sort_values` and `head` methods.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5pgLBsB5VAt"
   },
   "outputs": [],
   "source": [
    "most_populous_df = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwxNhWmO5VAu"
   },
   "outputs": [],
   "source": [
    "most_populous_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLZpbPAL5VAu"
   },
   "source": [
    "**Q5: Add a new column in `countries_df` to record the overall GDP per country (product of population & per capita GDP).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpUyBTUn5VAu"
   },
   "outputs": [],
   "source": [
    "countries_df['gdp'] = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eNPSxIps5VAu"
   },
   "outputs": [],
   "source": [
    "countries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkRMJMKY5VAz"
   },
   "source": [
    "**Q6: Count the number of countries for which the `total_tests` data is missing.**\n",
    "\n",
    "*Hint: Use the `.isna` method.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-tnyneM5VAz"
   },
   "outputs": [],
   "source": [
    "total_tests_missing = # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ep-5SQJa5VA0"
   },
   "outputs": [],
   "source": [
    "print(\"The data for total tests is missing for {} countries.\".format(int(total_tests_missing)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNqnnR5jzZw2"
   },
   "source": [
    "## Summary and Further Reading\n",
    "\n",
    "\n",
    "We've covered the following topics in this tutorial:\n",
    "\n",
    "- Reading a CSV file into a Pandas data frame\n",
    "- Retrieving data from Pandas data frames\n",
    "- Querying, soring, and analyzing data\n",
    "- Merging, grouping, and aggregation of data\n",
    "- Extracting useful information from dates\n",
    "- Basic plotting using line and bar charts\n",
    "- Writing data frames to CSV files\n",
    "\n",
    "\n",
    "Check out the following resources to learn more about Pandas:\n",
    "\n",
    "* User guide for Pandas: https://pandas.pydata.org/docs/user_guide/index.html\n",
    "* Python for Data Analysis (book by Wes McKinney - creator of Pandas): https://www.oreilly.com/library/view/python-for-data/9781491957653/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XliamO_o_Lm4"
   },
   "source": [
    "# Scikit-learn Basics\n",
    "\n",
    "The purpose of this guide is to illustrate some of the main features that scikit-learn provides. It assumes a very basic working knowledge of machine learning practices (model fitting, predicting, cross-validation, etc.).\n",
    "\n",
    "[`Scikit-learn`](https://scikit-learn.org/stable/getting_started.html) is an open source machine learning library that supports supervised and unsupervised learning. It also provides various tools for model fitting, data preprocessing, model selection, model evaluation, and many other utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "au2OJc2b_PfY"
   },
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffz6B92iREkl"
   },
   "source": [
    "## Fitting and Predicting: estimator basics\n",
    "\n",
    "Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators. Each estimator can be fitted to some data using its fit method.\n",
    "\n",
    "Here is a simple example where we fit a RandomForestClassifier to some very basic data:\n",
    "```python\n",
    ">>> from sklearn.ensemble import RandomForestClassifier\n",
    ">>> clf = RandomForestClassifier(random_state=0)\n",
    ">>> X = [[ 1,  2,  3],  # 2 samples, 3 features\n",
    "...      [11, 12, 13]]\n",
    ">>> y = [0, 1]  # classes of each sample\n",
    ">>> clf.fit(X, y)\n",
    "RandomForestClassifier(random_state=0)\n",
    "```\n",
    "The fit method generally accepts 2 inputs:\n",
    "\n",
    "- The samples matrix (or design matrix) X. The size of `X` is typically `(n_samples, n_features)`, which means that samples are represented as rows and features are represented as columns.\n",
    "\n",
    "- The target values y which are real numbers for regression tasks, or integers for classification (or any other discrete set of values). For unsupervized learning tasks, `y` does not need to be specified. `y` is usually 1d array where the `i`th entry corresponds to the target of the `i`th sample (row) of `X`.\n",
    "\n",
    "Both `X` and `y` are usually expected to be numpy arrays or equivalent array-like data types, though some estimators work with other formats such as sparse matrices.\n",
    "\n",
    "Once the estimator is fitted, it can be used for predicting target values of new data. You dont need to re-train the estimator:\n",
    "```python\n",
    ">>> clf.predict(X)  # predict classes of the training data\n",
    "array([0, 1])\n",
    ">>> clf.predict([[4, 5, 6], [14, 15, 16]])  # predict classes of new data\n",
    "array([0, 1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1r1wtKmUx99"
   },
   "source": [
    "### Exercise 1\n",
    "For this exercise we will use the famous [Iris dataset](https://archive.ics.uci.edu/ml/datasets/Iris/).\n",
    "\n",
    "Store the dataframe in the variable `iris_df` and split the features and labels using [`.iloc`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html). Store the feature dataframe in `X` and the labels in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpT_9MjhULGj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLtIDzfPUT_a"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(\n",
    "    data=np.c_[iris['data'], \n",
    "    iris['target']],\n",
    "    columns=iris['feature_names']+['target']\n",
    ") # ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "14cf9q51Vzsp"
   },
   "outputs": [],
   "source": [
    "assert isinstance(iris_df, pd.DataFrame)\n",
    "assert X.shape == (150,4)\n",
    "assert y.shape == (150,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pS1KqiBQaSpc"
   },
   "source": [
    "Use [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html?highlight=randomforest#sklearn.ensemble.RandomForestClassifier) class to fit the dataset. [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) is used to split the dataset into training and testing examples. Use the Training examples to fit the model and predict on the Test examples. Store the prediction resuls in `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4j5ToIAa85K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), random_state=0)\n",
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LVlP4sUucp9S"
   },
   "outputs": [],
   "source": [
    "assert isinstance(y_pred, np.ndarray)\n",
    "assert len(y_pred) == 38\n",
    "from sklearn.metrics import accuracy_score\n",
    "assert np.round(accuracy_score(y_test, y_pred), 2) == 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kfEaJXHV-9d"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Fitting a model to some data does not entail that it will predict well on unseen data. This needs to be directly evaluated. We have just seen the `train_test_split` helper that splits a dataset into train and test sets, but `scikit-learn` provides many other tools for model evaluation, in particular for [`cross-validation`](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).\n",
    "\n",
    "We here briefly show how to perform a 5-fold cross-validation procedure, using the `cross_validate` helper. Note that it is also possible to manually iterate over the folds, use different data splitting strategies, and use custom scoring functions.\n",
    "\n",
    "```python\n",
    ">>> from sklearn.datasets import make_regression\n",
    ">>> from sklearn.linear_model import LinearRegression\n",
    ">>> from sklearn.model_selection import cross_validate\n",
    "...\n",
    ">>> X, y = make_regression(n_samples=1000, random_state=0)\n",
    ">>> lr = LinearRegression()\n",
    "...\n",
    ">>> result = cross_validate(lr, X, y)  # defaults to 5-fold CV\n",
    ">>> result['test_score']  # r_squared score is high because dataset is easy\n",
    "array([1., 1., 1., 1., 1.])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHeFRthtePqO"
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "In this exercise, we will do a cross validation experiment on our iris dataset using [`LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression) model.\n",
    "\n",
    "The `LogisticRegression`(LR) model have a number of hyperparameters which can be tuned to find the best parameters for higher accuracy. In this exercise, you are free to use any [Model Selection](https://scikit-learn.org/stable/modules/classes.html?highlight=model_selection#module-sklearn.model_selection) classes to find the best parameter for the LR model.\n",
    "\n",
    "Store the predictions from the classifier on `X_test` in the variable `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OPB90-VaV2aF"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "estimator = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# ENTER YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZVaEWWAK0UJ"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "assert np.round(metrics.accuracy_score(y_pred=y_pred, y_true=y_test), 2) == 0.89"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yI2wGITymwJ8",
    "MATFZjsumwKA",
    "kHwJ6QGImwKB",
    "y0GZyvHvmwKD",
    "WvpBC0N6mwKF",
    "lm8J2z6JmwKJ",
    "pNZHjt0kmwKK",
    "exLSopeTmwKN",
    "UHDQN9aHmwKO",
    "Eoc-P8-RmwKS",
    "NcCRx4a7zZvi",
    "3-7Aa58PzZvl",
    "alXg8L55zZv4",
    "akWEhJiuzZwS",
    "WTXsX4NpzZwW",
    "mIZyC_fxzZwa",
    "vNTYKcZ9zZw2"
   ],
   "name": "Assignment 0",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
